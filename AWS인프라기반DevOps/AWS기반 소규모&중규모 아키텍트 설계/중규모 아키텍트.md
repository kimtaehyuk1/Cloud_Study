* 도커가 나온 이유
- 개발 환경을 그대로 복제해서 같은 환경에서 배포하고 싶다.
- 같은 서버에서 개발 환경을 여러개로 분리하고 싶다(같은서버내 다른 프로그램마다 독립적이어야지 서로 영향을 안미친다.)

가상환경이 저 두가지의 니즈를 어느정도 충족시키기는 하지만 비효율성이 생긴다! 어느부분이냐?
가상환경은 서버내에서 프로그램이 독립적으로 돌아가려면 일정 비율로 컴퓨팅파워를 분배해야된다. 즉 30대 70으로 나눴다고 가정했을때 30이 바쁘고 70이 놀고있어도
자동적으로 인지하지 못하고 70은 계속 놀고있는것이다. 

* 하지만 도커같은 경우에는 유동적으로 컴퓨팅 자원을 공유해서 쓴다 알아서 많이 쓰고 있는거 도와준다.
* 도커에서는 독립적인 프로그램들을 컨테이너 형태로 환경을 구분해준다라고 한다.
* 이미지를 통해 '같은 환경'의 가상 컴퓨터(컨테이너)를 무한히 생성할 수 있다.(auto scaling) ex)만약 개발자가 퇴사할때 이미지 남겨주면 설령 버젼을 다른것이라해도
남겨진 이미지 연장선에서 개발을 진행하면 된다.

* Docker-Compose
이거는 만약 컨테이너가 마이크로서비스라 서로 컨테이너간 유기적인 관계가 있을때(상호작용 해야 될 때) 그 위에 Docker-Compose라해서 이 컨테이너들을 포함할 수 있고,
또 이것을 통해서 컨테이너의 관계도 정의 할 수 있다.(필요하면 실습코드 보기)

django와 nginx에 도커파일 만들어서 컨테이너 실행해 웹서버 돌리는것은 영상참조 ( 필기 다 했는데 날라감 ㅠ)

※ AWS ECR(Elastic Container Registry)에 컨테이너 업로드
옵션1.
![image](https://user-images.githubusercontent.com/67897827/180708489-c2d66fb2-683c-4412-accf-8bd660779f1f.png)
개발을하고-> 도커이미지를 만들고-> 그 이미지를 외부 Registry에 등록을한다.(그 저장소는 Docker Registry일수도 있고, AWS ECR일수도 있다)->등록된 이미지를
ECS(Elastic Container Service)라는 서비스를 통해서 여러가지 EC2에 배포를 한다.

(실습)  
EC2만들기(Ubuntu로,Name:docker-ECR) -> PUTTY열고 빈칸에 ubuntu@만든EC2 퍼블릭IPv4 DNS 붙여넣기하고 SSH Auth에 allow체크해주고 밑에 ppk붙여넣기
-> curl -fsSL https://get.docker.com/ | sudo sh 명령어로 도커 다운받고 sudo usermod -aG docker $USER로 권한설정하고 mkdir docker-sever파일 만들어주고 cd로 가기
-> git clone (깃허브 올려놓은 code에 SSH에 주소있는거 복사해서 붙여넣기).git -> ls하면 fastcampus_test 있을거고 cd로 들어가기-> vi Dockerfile 만들어주기 insert모드에서

FROM python:3.6.7

ENV PYTHONUNBUFFERED 1

RUN apt-get -y update
RUN apt-get -y install vim

RUN mkdir /srv/docker-server
ADD . /srv/docker-server

WORKDIR /srv/docker-server

RUN pip install --upgrade pip
RUN pip install -r requirements.txt

EXPOSE 8000
CMD ["python", "manage.py", "runserver", "0.0.0.0:8000"]

이거 쳐주고 wq로 저장해서 그 후 도커파일을 통해서 이미지 생성하는 docker build -t ecr/django . 이거 하면 permission deny나오는데 putty창 꺼서 다시 드가서 다시 fastcampus_test 로 드가서 build명령어 똑같이 다시 치면 실행 된다. -> 다음으로 도커에 tag달아줘야 된다 docker tag (만든 이미지 ID) (AWS ECS 리포지토리에서 만든 URI)
이렇게 명령어 쳐주기! 이 말은 이 이미지를 리포지토리에 올릴거라는 tag다는거다 (참고로 docker image 치면 만든 이미지 ID 볼수 있다)
-> aws ecr get-login --no-include-email --region us-east-2 이건 ecr에 접근하고 싶다는 커맨드라이다 이게 바로 AWS CLI인데 아마 안되고 sudo apt install awscli 나올거다
이거 쳐서 실행해서 다시 저거 쳐주면 되는데 또 aws configure 이라는것이 뜨면서 니가 aws사용 유저를 알려라고 뜰거다(밑에 설명) 다하고나서 다시 명령어 치기
-> 긴 문자열이 생길거다 그거 그대로 복사해서 복붙해서 쳐주기 그럼 로그인 성공 뜬다 -> 마지막으로 내가 만든 이미지를 저장소에 푸쉬하기위해 docker push (AWS ECS 리포지토리에서 만든 URI) 


(옵션 1 실행하기 위한 저장소 생성)  
AWS ECS드가서 왼쪽 바에 리포지토리 클릭 생성 누르기 -> 리포지토리 이름에 / fargate_django 이름 쓰고 생성(하나의 폴더 즉 저장소가 생긴거다)

(옵션 1 실행하기 위한 aws configure)  
aws IAM 드가기 -> 왼쪽바에 사용자 드가기 사용자추가해서 이름을 awscli라고 이름짓고 액세스 유형을 프로그램방식 체크 -> 권한 설정을 기존정책에 연결눌러 AdministratorAccess
누르기 -> 키는 name:admin 후 다음눌러 사용자 만들기하면 액세스 키 ID가 나와있다 putty창에 ID와 시크릿키 치고 나머지물어보는건 걍 엔터 치면 날 증명한거다 그 후 다시 aws 명령어 쳐보기





옵션2.
![image](https://user-images.githubusercontent.com/67897827/180709641-bbee6831-6bc2-413d-9536-dd47c3a538aa.png)
등록소에 저장하는거 까지는 똑같은데 여기서 빼서 배포를 하는 방식이 다르다 이전까지 배포할때 EC2서버를 만들어서 거기다가(EC2를 거쳐서 배포를 했는데)
그 EC2가 빠지고 마치 ECS와 EC2를 동시에 활용하는것 같은 효과를 주는것이다.

(AWS ECR에 우리가 이미지 업로드 한 이후 실습) -> ECS 클러스터(컨테이너들을 구분해주는 구분영역) 를 생성해줘야한다.(비슷한얘들끼리 묶어서) -> 네트워킹 전용(Fargate쓸거니까)
->이름,vpc는생성안해도되고,컨테이너인사이트활성화체크->생성누르기
-> 작업(작업은 클러스터 내부에 있는 세부 행위인데, 작업안에 컨테이너가 있다.)생성 하기 위해 옆에 작업 정의 생성 -> FARGATE클릭 ->이름,작업크기정하기, 컨테이너 추가 눌러서
이름, 이미지칸에는 우리가 이미 만들어논 ECR에서 이미지 URL따서 복붙,메모리제한 128, 포트매핑 8000,끝 -> 생성
-> 작업 실행 누르기 -> 시작유형 FARGATE,클러스터는 방금만들어논거,작업개수1,클러스터VPC는 기본적인거 서브넷도 있는거다누르기,보안그룹은 편집눌러서 인바운드8000허용식으로
편집하고->작업실행


실습
![image](https://user-images.githubusercontent.com/67897827/180710228-e655cb3d-fac9-4c49-8698-ff5dd48b878e.png)
전에 이미지를 만들었을때는 우리는 이미지가 두개여서 EC2안에서 docker-compose로 해서 만든후 nginx는 잔고가 선행되야 돌아가니까 docker-compose.yml에 depense on에 어쩌구
했었는데 여기서 AWS Fargate를 활용하려면 AWS CLI를 통해서 만들어서 두 ECR 관계 규명후 AWS Fargate로 배포하는거


※ AWS CLI
- AWS 명령줄 인터페이스(CLI)는 AWS 서비스를 관리하는 통합 도구입니다. 도구 하나만
다운로드하여 구성하면 여러 AWS 서비스를 명령줄에서 제어하고 스크립트를 통해
자동화할 수 있습니다.(GUI를 하면 편하기는 한데 벙거롭다. 자동화를 못한다.)
- AWS CLI는 Amazon S3에서 효율적으로 파일을 보내고 받을 수 있는 간단한 새 파일
명령 세트를 제공합니다
